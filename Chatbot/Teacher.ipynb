{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0b6b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version     Editable project location\n",
      "---------------------------------------- ----------- -------------------------\n",
      "absl-py                                  2.1.0\n",
      "aiofiles                                 23.2.1\n",
      "aiohttp                                  3.9.5\n",
      "aiosignal                                1.3.1\n",
      "altair                                   5.3.0\n",
      "annotated-types                          0.6.0\n",
      "anyascii                                 0.3.2\n",
      "anyio                                    4.3.0\n",
      "asgiref                                  3.8.1\n",
      "async-timeout                            4.0.3\n",
      "attrs                                    23.2.0\n",
      "audioread                                3.0.1\n",
      "Babel                                    2.14.0\n",
      "backoff                                  2.2.1\n",
      "bangla                                   0.0.2\n",
      "bcrypt                                   4.1.2\n",
      "blinker                                  1.7.0\n",
      "blis                                     0.7.11\n",
      "bnnumerizer                              0.0.2\n",
      "bnunicodenormalizer                      0.1.6\n",
      "build                                    1.2.1\n",
      "cachetools                               5.3.3\n",
      "catalogue                                2.0.10\n",
      "certifi                                  2024.2.2\n",
      "cffi                                     1.16.0\n",
      "charset-normalizer                       3.3.2\n",
      "chroma-hnswlib                           0.7.3\n",
      "chromadb                                 0.4.24\n",
      "click                                    8.1.7\n",
      "cloudpathlib                             0.16.0\n",
      "coloredlogs                              15.0.1\n",
      "confection                               0.1.4\n",
      "contourpy                                1.2.1\n",
      "coqpit                                   0.0.17\n",
      "cycler                                   0.12.1\n",
      "cymem                                    2.0.8\n",
      "Cython                                   3.0.10\n",
      "dataclasses-json                         0.6.4\n",
      "dateparser                               1.1.8\n",
      "decorator                                5.1.1\n",
      "Deprecated                               1.2.14\n",
      "distro                                   1.9.0\n",
      "docopt                                   0.6.2\n",
      "einops                                   0.7.0\n",
      "encodec                                  0.1.1\n",
      "exceptiongroup                           1.2.1\n",
      "fastapi                                  0.110.2\n",
      "ffmpy                                    0.3.2\n",
      "filelock                                 3.13.4\n",
      "Flask                                    3.0.3\n",
      "flatbuffers                              24.3.25\n",
      "fonttools                                4.51.0\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2024.3.1\n",
      "g2pkk                                    0.1.2\n",
      "google-auth                              2.29.0\n",
      "googleapis-common-protos                 1.63.0\n",
      "gradio                                   3.50.2\n",
      "gradio_client                            0.6.1\n",
      "greenlet                                 3.0.3\n",
      "grpcio                                   1.62.2\n",
      "gruut                                    2.2.3\n",
      "gruut-ipa                                0.13.0\n",
      "gruut-lang-de                            2.0.0\n",
      "gruut-lang-en                            2.0.0\n",
      "gruut-lang-es                            2.0.0\n",
      "gruut-lang-fr                            2.0.2\n",
      "h11                                      0.14.0\n",
      "hangul-romanize                          0.1.0\n",
      "httpcore                                 1.0.5\n",
      "httptools                                0.6.1\n",
      "httpx                                    0.27.0\n",
      "huggingface-hub                          0.22.2\n",
      "humanfriendly                            10.0\n",
      "idna                                     3.7\n",
      "importlib-metadata                       7.0.0\n",
      "importlib_resources                      6.4.0\n",
      "inflect                                  7.2.0\n",
      "itsdangerous                             2.2.0\n",
      "jamo                                     0.4.1\n",
      "jieba                                    0.42.1\n",
      "Jinja2                                   3.1.3\n",
      "joblib                                   1.4.0\n",
      "jsonlines                                1.2.0\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              2.4\n",
      "jsonschema                               4.21.1\n",
      "jsonschema-specifications                2023.12.1\n",
      "kiwisolver                               1.4.5\n",
      "kubernetes                               29.0.0\n",
      "langchain                                0.1.16\n",
      "langchain-community                      0.0.34\n",
      "langchain-core                           0.1.45\n",
      "langchain-text-splitters                 0.0.1\n",
      "langcodes                                3.3.0\n",
      "langsmith                                0.1.49\n",
      "lazy_loader                              0.4\n",
      "librosa                                  0.10.0\n",
      "llvmlite                                 0.42.0\n",
      "Markdown                                 3.6\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.1.5\n",
      "marshmallow                              3.21.1\n",
      "matplotlib                               3.8.4\n",
      "mdurl                                    0.1.2\n",
      "mmh3                                     4.1.0\n",
      "monotonic                                1.6\n",
      "more-itertools                           10.2.0\n",
      "mpmath                                   1.3.0\n",
      "msgpack                                  1.0.8\n",
      "multidict                                6.0.5\n",
      "murmurhash                               1.0.10\n",
      "mutagen                                  1.47.0\n",
      "mypy-extensions                          1.0.0\n",
      "networkx                                 2.8.8\n",
      "nltk                                     3.8.1\n",
      "num2words                                0.5.13\n",
      "numba                                    0.59.1\n",
      "numpy                                    1.22.0\n",
      "nvidia-cublas-cu12                       12.1.3.1\n",
      "nvidia-cuda-cupti-cu12                   12.1.105\n",
      "nvidia-cuda-nvrtc-cu12                   12.1.105\n",
      "nvidia-cuda-runtime-cu12                 12.1.105\n",
      "nvidia-cudnn-cu12                        8.9.2.26\n",
      "nvidia-cufft-cu12                        11.0.2.54\n",
      "nvidia-curand-cu12                       10.3.2.106\n",
      "nvidia-cusolver-cu12                     11.4.5.107\n",
      "nvidia-cusparse-cu12                     12.1.0.106\n",
      "nvidia-nccl-cu12                         2.19.3\n",
      "nvidia-nvjitlink-cu12                    12.4.127\n",
      "nvidia-nvtx-cu12                         12.1.105\n",
      "oauthlib                                 3.2.2\n",
      "onnxruntime                              1.17.3\n",
      "openai                                   1.23.2\n",
      "openai-whisper                           20231117\n",
      "opentelemetry-api                        1.24.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.24.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.24.0\n",
      "opentelemetry-instrumentation            0.45b0\n",
      "opentelemetry-instrumentation-asgi       0.45b0\n",
      "opentelemetry-instrumentation-fastapi    0.45b0\n",
      "opentelemetry-proto                      1.24.0\n",
      "opentelemetry-sdk                        1.24.0\n",
      "opentelemetry-semantic-conventions       0.45b0\n",
      "opentelemetry-util-http                  0.45b0\n",
      "orjson                                   3.10.1\n",
      "overrides                                7.7.0\n",
      "packaging                                23.2\n",
      "pandas                                   1.5.3\n",
      "pillow                                   10.3.0\n",
      "pip                                      24.0\n",
      "platformdirs                             4.2.0\n",
      "pooch                                    1.8.1\n",
      "posthog                                  3.5.0\n",
      "preshed                                  3.0.9\n",
      "protobuf                                 4.25.3\n",
      "psutil                                   5.9.8\n",
      "pulsar-client                            3.5.0\n",
      "pyasn1                                   0.6.0\n",
      "pyasn1_modules                           0.4.0\n",
      "pycparser                                2.22\n",
      "pydantic                                 2.7.0\n",
      "pydantic_core                            2.18.1\n",
      "pydub                                    0.25.1\n",
      "Pygments                                 2.17.2\n",
      "pynndescent                              0.5.12\n",
      "pyparsing                                3.1.2\n",
      "pypdf                                    4.2.0\n",
      "PyPika                                   0.48.9\n",
      "pypinyin                                 0.51.0\n",
      "pyproject_hooks                          1.0.0\n",
      "pysbd                                    0.3.4\n",
      "python-crfsuite                          0.9.10\n",
      "python-dateutil                          2.9.0.post0\n",
      "python-dotenv                            1.0.1\n",
      "python-multipart                         0.0.9\n",
      "pytz                                     2024.1\n",
      "PyYAML                                   6.0.1\n",
      "referencing                              0.34.0\n",
      "regex                                    2024.4.16\n",
      "requests                                 2.31.0\n",
      "requests-oauthlib                        2.0.0\n",
      "rich                                     13.7.1\n",
      "rpds-py                                  0.18.0\n",
      "rsa                                      4.9\n",
      "safetensors                              0.4.3\n",
      "scikit-learn                             1.4.2\n",
      "scipy                                    1.11.4\n",
      "semantic-version                         2.10.0\n",
      "setuptools                               69.5.1\n",
      "shellingham                              1.5.4\n",
      "six                                      1.16.0\n",
      "smart-open                               6.4.0\n",
      "sniffio                                  1.3.1\n",
      "soundfile                                0.12.1\n",
      "soxr                                     0.3.7\n",
      "spacy                                    3.7.4\n",
      "spacy-legacy                             3.0.12\n",
      "spacy-loggers                            1.0.5\n",
      "SQLAlchemy                               2.0.29\n",
      "srsly                                    2.4.8\n",
      "starlette                                0.37.2\n",
      "SudachiDict-core                         20240409\n",
      "SudachiPy                                0.6.8\n",
      "sympy                                    1.12\n",
      "tenacity                                 8.2.3\n",
      "tensorboard                              2.16.2\n",
      "tensorboard-data-server                  0.7.2\n",
      "thinc                                    8.2.3\n",
      "threadpoolctl                            3.4.0\n",
      "tiktoken                                 0.6.0\n",
      "tokenizers                               0.19.1\n",
      "tomli                                    2.0.1\n",
      "toolz                                    0.12.1\n",
      "torch                                    2.2.2\n",
      "torchaudio                               2.2.2\n",
      "tqdm                                     4.66.2\n",
      "trainer                                  0.0.36\n",
      "transformers                             4.40.0\n",
      "triton                                   2.2.0\n",
      "TTS                                      0.22.0      /home/bargh1/TTS\n",
      "typeguard                                4.2.1\n",
      "typer                                    0.9.4\n",
      "typing_extensions                        4.11.0\n",
      "typing-inspect                           0.9.0\n",
      "tzdata                                   2024.1\n",
      "tzlocal                                  5.2\n",
      "umap-learn                               0.5.6\n",
      "Unidecode                                1.3.8\n",
      "urllib3                                  2.2.1\n",
      "uvicorn                                  0.29.0\n",
      "uvloop                                   0.19.0\n",
      "wasabi                                   1.1.2\n",
      "watchfiles                               0.21.0\n",
      "weasel                                   0.3.4\n",
      "websocket-client                         1.7.0\n",
      "websockets                               11.0.3\n",
      "Werkzeug                                 3.0.2\n",
      "wheel                                    0.43.0\n",
      "wrapt                                    1.16.0\n",
      "yarl                                     1.9.4\n",
      "zipp                                     3.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b694848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\r\n",
      "Version: 0.1.16\r\n",
      "Summary: Building applications with LLMs through composability\r\n",
      "Home-page: https://github.com/langchain-ai/langchain\r\n",
      "Author: \r\n",
      "Author-email: \r\n",
      "License: MIT\r\n",
      "Location: /home/bargh1/Teacher/lib/python3.10/site-packages\r\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, jsonpatch, langchain-community, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2183ad95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bargh1/TTS\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c90cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bargh1/TTS\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5b1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/bargh1/Teacher/lib/python3.10/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac65d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d502a865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cc892f34-9370-4b86-9205-9db328c427b2\t pyproject.toml\r\n",
      " checkpoints\t\t\t\t README.md\r\n",
      " chroma.sqlite3\t\t\t\t recipes\r\n",
      " CITATION.cff\t\t\t\t requirements.dev.txt\r\n",
      " CODE_OF_CONDUCT.md\t\t\t requirements.ja.txt\r\n",
      " CODE_OWNERS.rst\t\t\t requirements.notebooks.txt\r\n",
      " CONTRIBUTING.md\t\t\t requirements.txt\r\n",
      " cross_dataset.ipynb\t\t\t run_bash_tests.sh\r\n",
      " Dockerfile\t\t\t\t S24-NLP-Syllabus-v1.pdf\r\n",
      " dockerfiles\t\t\t\t scripts\r\n",
      " docs\t\t\t\t\t setup.cfg\r\n",
      " flagged\t\t\t\t setup.py\r\n",
      " Hindi_checkpoints\t\t\t'Teacher Assistant chatbot.ipynb'\r\n",
      " hubconf.py\t\t\t\t Teacher.ipynb\r\n",
      " images\t\t\t\t\t tests\r\n",
      " LICENSE.txt\t\t\t\t TTS\r\n",
      " LinearAlgebraReview-StanfordCS229.pdf\t TTS.egg-info\r\n",
      " Makefile\t\t\t\t wandb\r\n",
      " MANIFEST.in\t\t\t\t ZD_output\r\n",
      "'Narges_Mohammadi1 (1).mp3'\t\t'ZD_trainer (copy).py'\r\n",
      " notebooks\t\t\t\t ZD_trainer.ipynb\r\n",
      " Notes01-wordvecs1.pdf\t\t\t ZD_trainer.py\r\n",
      " Notes03-neuralnets.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b4f2f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bargh1/.local/lib/python3.10/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "import soundfile as sf  # Ensure this library is installed\n",
    "import gradio as gr\n",
    "import whisper\n",
    "import gradio\n",
    "from IPython.display import Audio\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43047034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84e8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip = 0\n",
    "device = torch.device(f\"cuda:{chip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48dcd9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd03f07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.available_models()\n",
    "model1 = whisper.load_model(\"large-v2\",device = device)\n",
    "model1.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c5102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bargh1/Teacher/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created and persisted successfully.\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://7fc91c42970013126e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7fc91c42970013126e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def split_into_sentences(text, max_length=200):\n",
    "    # Split the text into sentences based on punctuation marks\n",
    "    sentences = []\n",
    "    current_sentence = \"\"\n",
    "    last_punctuation_index = 0  # To remember the last punctuation position\n",
    "\n",
    "    for i, char in enumerate(text):\n",
    "        current_sentence += char\n",
    "        if char in ['.', '!', '?']:\n",
    "            current_sentence = current_sentence[:-1] + ' ' + char\n",
    "            last_punctuation_index = i  # Update the last known punctuation position\n",
    "\n",
    "        if len(current_sentence) >= max_length:\n",
    "            # If we reach max length, we should cut at the last punctuation\n",
    "            if last_punctuation_index > 0:\n",
    "                # Take up to the last punctuation\n",
    "                sentences.append(current_sentence[:last_punctuation_index+1].strip())\n",
    "                # Start new sentence after the last punctuation\n",
    "                current_sentence = current_sentence[last_punctuation_index+1:].strip()\n",
    "                last_punctuation_index = 0  # Reset punctuation index\n",
    "            else:\n",
    "                # No punctuation was found, but we need to split anyway\n",
    "                sentences.append(current_sentence.strip())\n",
    "                current_sentence = \"\"\n",
    "\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence.strip())\n",
    "\n",
    "    return sentences\n",
    "def synthesize_speech(choice,text, speaker_wav=\"Narges_Mohammadi1 (1).mp3\"):\n",
    "    # Load the configuration\n",
    "    config_path = \"checkpoints/config.json\"\n",
    "    config = XttsConfig()\n",
    "    config.load_json(config_path)\n",
    "\n",
    "    # Initialize the model from the configuration\n",
    "    model = Xtts.init_from_config(config)\n",
    "\n",
    "    # Load the model checkpoint\n",
    "    checkpoint_dir = \"checkpoints\"\n",
    "    model.load_checkpoint(config, checkpoint_dir=checkpoint_dir, eval=True)\n",
    "\n",
    "    # Move the model to GPU if you're using CUDA (uncomment the next line if needed)\n",
    "    model.cuda()\n",
    "\n",
    "    # Split the input text into smaller sentences\n",
    "    sentences = split_into_sentences(text)\n",
    "\n",
    "    # Create a list to store the paths of synthesized audio files\n",
    "    audio_file_paths = []\n",
    "    \n",
    "    lang = set_lang(choice)\n",
    "    print(lang)\n",
    "\n",
    "    # Synthesize speech for each sentence\n",
    "    for sentence in sentences:\n",
    "        # Synthesize speech\n",
    "        outputs = model.synthesize(\n",
    "            sentence,\n",
    "            config,\n",
    "            speaker_wav=speaker_wav,\n",
    "            gpt_cond_len=3,\n",
    "            language=lang\n",
    "        )\n",
    "\n",
    "        # Extract the audio data\n",
    "        audio_data = outputs['wav']\n",
    "        samplerate = 22050  # Adjust based on your model's output sample rate\n",
    "\n",
    "        # Save the audio data to a temporary file\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "            sf.write(temp_file.name, audio_data, samplerate)\n",
    "            audio_file_paths.append(temp_file.name)\n",
    "\n",
    "    # Concatenate the audio files\n",
    "    combined_audio = AudioSegment.empty()\n",
    "    for audio_file_path in audio_file_paths:\n",
    "        audio_segment = AudioSegment.from_wav(audio_file_path)\n",
    "        combined_audio += audio_segment\n",
    "\n",
    "    # Save the combined audio to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "        combined_audio.export(temp_file.name, format=\"wav\")\n",
    "        combined_audio_path = temp_file.name\n",
    "\n",
    "    # Return the path to the combined audio file\n",
    "    return combined_audio_path\n",
    "# Replace YOUR_OPENAI_API_KEY with your actual OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-mqaHLOQf5awVkPM02F9OT3BlbkFJQAHciKYmKhIMkcUXtNHb\"\n",
    "\n",
    "def load_and_process_pdfs(pdf_paths):\n",
    "    all_pages = []\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load_and_split()\n",
    "        all_pages.extend(pages)  # Collect pages from all PDFs in a single list\n",
    "\n",
    "    return all_pages\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Load multiple PDF files\n",
    "pdf_paths = [\n",
    "    'Notes01-wordvecs1.pdf',\n",
    "    'Notes03-neuralnets.pdf',\n",
    "    'S24-NLP-Syllabus-v1.pdf',\n",
    "]\n",
    "all_pages = load_and_process_pdfs(pdf_paths)\n",
    "\n",
    "# Now use these pages to create embeddings and store them in a vector database\n",
    "vectordb = Chroma.from_documents(all_pages, embedding=embeddings, persist_directory=\".\")\n",
    "\n",
    "# Persist the vector database to disk\n",
    "vectordb.persist()\n",
    "\n",
    "print(\"Vector database created and persisted successfully.\")\n",
    "\n",
    "def transcribe(choice,audio_file_path):\n",
    "    try:\n",
    "        lang = set_lang(choice)\n",
    "        # Load the audio file\n",
    "        audio = whisper.load_audio(audio_file_path)\n",
    "\n",
    "        # Transcribe the audio\n",
    "        audio_to_text = model1.transcribe(audio, language=\"en\", fp16=False)[\"text\"]\n",
    "        print(\"Transcribed Text:\", audio_to_text)\n",
    "\n",
    "        # Assuming vectordb is already initialized correctly\n",
    "        pdf_ga = ChatVectorDBChain.from_llm(\n",
    "            ChatOpenAI(temperature=1.2, model_name=\"gpt-4-turbo\"),\n",
    "            vectordb, return_source_documents=True\n",
    "        )\n",
    "\n",
    "        result = pdf_ga({\"question\": f\"Please provide the answer in {choice}: {audio_to_text}\", \"chat_history\": \"\"})\n",
    "        result_in_farsi = result[\"answer\"]\n",
    "        audio_result = synthesize_speech(choice,result_in_farsi)\n",
    "\n",
    "        return audio_to_text, result_in_farsi, audio_result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "        return \"Error occurred during transcription\", \"\", None\n",
    "    \n",
    "def set_lang(choice):\n",
    "    if choice ==\"English\":\n",
    "        lang=\"en\"\n",
    "    if choice ==\"Hindi\":\n",
    "        lang=\"hi\"\n",
    "    if choice == \"Persian\":\n",
    "        lang = \"fa\"\n",
    "    return lang\n",
    "\n",
    "choices=[\"English\",\"Hindi\",\"Persian\"]\n",
    "output_1 = gr.Textbox(label=\"Speech to Text (Whisper)\")\n",
    "output_2 = gr.Textbox(label=\"ChatGPT Output\")\n",
    "#output_3 = gr.Audio(label=\"ChatGPT output to audio via TTR\", upload=\"output.wav\")\n",
    "output_3 = gr.Audio(label=\"ChatGPT output to audio via TTR\")\n",
    "gr.Interface(\n",
    "    title='Persian Teacher assistant',\n",
    "    fn=transcribe,\n",
    "    inputs=[gr.Radio(choices),\n",
    "        gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "    ],\n",
    "    outputs=[output_1, output_2, output_3]\n",
    ").launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41136ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "\n",
    "# def set_lang(choice):\n",
    "#     lang=choice\n",
    "#     return f\"You selected{lang}.\"\n",
    "\n",
    "# choices=[\"English\",\"Hindi\",\"Persian\"]\n",
    "# radio = gr.Interface(\n",
    "#     fn=set_lang,\n",
    "#     inputs=gr.Radio(choices),\n",
    "#     outputs=[\"text\"],\n",
    "#     title=\"Set Language\",\n",
    "# )\n",
    "\n",
    "# radio.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "\n",
    "# def set_lang(English,Hindi,Persian):\n",
    "#     if English:\n",
    "#         lang = \"Eng\"\n",
    "#     if Hindi:\n",
    "#         lang = \"Hi\" \n",
    "#     if Persian:\n",
    "#         lang = \"Per\" \n",
    "#     greeting = f\"You have selected{lang}\"\n",
    "#     return greeting\n",
    "\n",
    "# demo = gr.Interface(\n",
    "#     set_lang,\n",
    "#     inputs=[\"checkbox\",\"checkbox\", \"checkbox\"],\n",
    "#     outputs=[\"text\"],\n",
    "# )\n",
    "# if __name__ == \"__main__\":\n",
    "#     demo.launch()\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c3cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
