{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n"
      ],
      "metadata": {
        "id": "rPFGhqNfekC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer\n"
      ],
      "metadata": {
        "id": "4dyTX7PSBg8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n"
      ],
      "metadata": {
        "id": "Afz4bjryBt_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Connect to Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OXOJI0UMcDst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import whisper\n",
        "\n",
        "def transcribe_audio_to_text(audio_path):\n",
        "    \"\"\"\n",
        "    Transcribe the given audio file to text using the Whisper model.\n",
        "    \"\"\"\n",
        "    # Load the Whisper model\n",
        "    model = whisper.load_model(\"large-v3\")\n",
        "\n",
        "    # Load and transcribe the audio file\n",
        "    result = model.transcribe(audio_path, language=\"fa\")\n",
        "\n",
        "    # Extract the transcribed text\n",
        "    transcribed_text = result[\"text\"]\n",
        "\n",
        "    return transcribed_text\n",
        "\n",
        "def transcribe_folder_to_csv(folder_path, csv_path):\n",
        "    \"\"\"\n",
        "    Transcribe all .wav files in the given folder and store the results in a CSV file,\n",
        "    skipping files that have already been transcribed.\n",
        "    \"\"\"\n",
        "    already_transcribed = set()\n",
        "    # Check if the CSV file exists and read already transcribed filenames\n",
        "    if os.path.exists(csv_path):\n",
        "        with open(csv_path, mode='r', newline='', encoding='utf-8') as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader, None)  # Skip the header\n",
        "            already_transcribed = {rows[0] for rows in reader}\n",
        "\n",
        "    # Open the CSV file in append mode\n",
        "    with open(csv_path, mode='a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # If the file was newly created, write the header\n",
        "        if not already_transcribed:\n",
        "            writer.writerow([\"Filename\", \"Transcribed Text\"])\n",
        "\n",
        "        # Loop through all files in the folder\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(\".wav\") and filename not in already_transcribed:\n",
        "                # Full path to the current audio file\n",
        "                audio_path = os.path.join(folder_path, filename)\n",
        "\n",
        "                # Transcribe the audio to text\n",
        "                transcribed_text = transcribe_audio_to_text(audio_path)\n",
        "\n",
        "                # Write the filename and transcribed text to the CSV\n",
        "                writer.writerow([filename, transcribed_text])\n",
        "                print(f\"Transcribed: {filename}\")\n",
        "\n",
        "# Example usage\n",
        "folder_path = \"/content/drive/MyDrive/AutoMOS/VITS\"\n",
        "csv_path = \"/content/drive/MyDrive/AutoMOS/VITS/Transcribed_VITS.csv\"\n",
        "transcribe_folder_to_csv(folder_path, csv_path)\n"
      ],
      "metadata": {
        "id": "fYaX7RhsbMq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/AutoMOS/XTTS/"
      ],
      "metadata": {
        "id": "OabkgBzAnrcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def merge_csv_files(transcribed_csv_path, metadata_csv_path, output_csv_path):\n",
        "    \"\"\"\n",
        "    Merge two CSV files based on the \"Filename\" column and save the result to a new CSV file.\n",
        "\n",
        "    Args:\n",
        "        transcribed_csv_path (str): The path to the CSV file with transcribed text.\n",
        "        metadata_csv_path (str): The path to the CSV file with additional metadata.\n",
        "        output_csv_path (str): The path where the merged CSV file will be saved.\n",
        "    \"\"\"\n",
        "    # Load the CSV files into DataFrames\n",
        "    transcribed_df = pd.read_csv(transcribed_csv_path)\n",
        "    metadata_df = pd.read_csv(metadata_csv_path)\n",
        "\n",
        "    # Merge the DataFrames on the \"Filename\" column\n",
        "    merged_df = pd.merge(transcribed_df, metadata_df, on=\"Filename\", how=\"inner\")\n",
        "\n",
        "    # Save the merged DataFrame to a new CSV file\n",
        "    merged_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Merged file saved to {output_csv_path}\")\n",
        "\n",
        "# Example usage\n",
        "transcribed_csv_path = \"/content/drive/MyDrive/AutoMOS/XTTS/Transcribed_Metadata_XTTS - Transcribed_Metadata_XTTS.csv\"\n",
        "metadata_csv_path = \"/content/drive/MyDrive/AutoMOS/XTTS/Metadata_XTTS.csv\"\n",
        "output_csv_path = \"Merged_XTTS.csv\"\n",
        "\n",
        "merge_csv_files(transcribed_csv_path, metadata_csv_path, output_csv_path)\n"
      ],
      "metadata": {
        "id": "8NTrL0qWo05U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import csv\n",
        "\n",
        "def transcribe_audio_to_text(audio_path):\n",
        "    \"\"\"\n",
        "    Transcribe the given audio file to text using the Whisper model.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): The path to the audio file to transcribe.\n",
        "\n",
        "    Returns:\n",
        "        str: The transcribed text.\n",
        "    \"\"\"\n",
        "    # Load the Whisper model\n",
        "    model = whisper.load_model(\"large-v3\")\n",
        "\n",
        "    # Load and transcribe the audio file\n",
        "    result = model.transcribe(audio_path, language=\"fa\")\n",
        "\n",
        "    # Extract the transcribed text\n",
        "    transcribed_text = result[\"text\"]\n",
        "\n",
        "    return transcribed_text\n",
        "\n",
        "def transcribe_folder_to_csv(folder_path, csv_path):\n",
        "    \"\"\"\n",
        "    Transcribe all .wav files in the given folder and store the results in a CSV file.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder containing .wav files.\n",
        "        csv_path (str): The path to the CSV file to store the transcriptions.\n",
        "    \"\"\"\n",
        "    # Prepare to write to the CSV file\n",
        "    with open(csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Write the header\n",
        "        writer.writerow([\"Filename\", \"Transcribed Text\"])\n",
        "\n",
        "        # Loop through all files in the folder\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(\".wav\"):\n",
        "                # Full path to the current audio file\n",
        "                audio_path = os.path.join(folder_path, filename)\n",
        "\n",
        "                # Transcribe the audio to text\n",
        "                transcribed_text = transcribe_audio_to_text(audio_path)\n",
        "\n",
        "                # Write the filename and transcribed text to the CSV\n",
        "                writer.writerow([filename, transcribed_text])\n",
        "                print(f\"Transcribed: {filename}\")\n",
        "\n",
        "# Path to the folder containing .wav files\n",
        "folder_path = \"/content/drive/MyDrive/AutoMOS/XTTS\"\n",
        "\n",
        "# Path to the CSV file where results will be stored\n",
        "csv_path = \"/content/drive/MyDrive/AutoMOS/XTTS/Transcribed_XTTS.csv\"\n",
        "\n",
        "# Transcribe all .wav files in the folder and store the results in the CSV file\n",
        "transcribe_folder_to_csv(folder_path, csv_path)"
      ],
      "metadata": {
        "id": "i150-UHef2G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the two CSV files into pandas DataFrames\n",
        "metadata_vits = pd.read_csv('/content/drive/MyDrive/AutoMOS/VITS/Metadata_VITS.csv')\n",
        "transcribed_metadata_vits = pd.read_csv('/content/drive/MyDrive/AutoMOS/VITS/Transcribed_VITS.csv')\n",
        "\n",
        "# Merge the DataFrames based on the 'Filename' column\n",
        "merged_df_vits = pd.merge(metadata_vits, transcribed_metadata_vits, on='Filename', how='left')\n",
        "\n",
        "# Add a new column named 'Transcribed' to 'Metadata_VITS.csv'\n",
        "merged_df_vits['Transcribed'] = merged_df_vits['Transcribed Text']\n",
        "\n",
        "# Drop unnecessary columns from the merged DataFrame\n",
        "merged_df_vits.drop(columns=['Transcribed Text'], inplace=True)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "merged_df_vits.to_csv('Merged_Metadata_VITS.csv', index=False)\n",
        "\n",
        "print(\"Merged CSV file saved successfully.\")\n"
      ],
      "metadata": {
        "id": "LKBByXo5htgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort the result and merge it to original transcribe"
      ],
      "metadata": {
        "id": "0aPQevT9G1RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def sort_csv_by_filename(csv_path, sorted_csv_path):\n",
        "    \"\"\"\n",
        "    Sort a CSV file by filenames mentioned in one of its columns.\n",
        "\n",
        "    Args:\n",
        "        csv_path (str): The path to the original CSV file.\n",
        "        sorted_csv_path (str): The path to save the sorted CSV file.\n",
        "    \"\"\"\n",
        "    with open(csv_path, mode='r', encoding='utf-8') as file:\n",
        "        reader = csv.reader(file)\n",
        "        header = next(reader)  # Capture the header\n",
        "        records = list(reader)\n",
        "\n",
        "    # Assuming the filename is in the first column, sort the records\n",
        "    # Extracting the numeric part of the filename for sorting\n",
        "    records.sort(key=lambda x: int(x[0][1:-4]))  # Assumes filenames are like 'v1.wav', 'v2.wav', etc.\n",
        "\n",
        "    # Write the sorted records back to a new CSV\n",
        "    with open(sorted_csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(header)  # Write the header first\n",
        "        writer.writerows(records)  # Then write the sorted records\n",
        "\n",
        "# Paths to the original and sorted CSV files\n",
        "csv_path = \"/content/drive/MyDrive/test voice/result.csv\"\n",
        "sorted_csv_path = \"/content/drive/MyDrive/test voice/sorted_results.csv\"\n",
        "\n",
        "# Sort the CSV file\n",
        "sort_csv_by_filename(csv_path, sorted_csv_path)\n"
      ],
      "metadata": {
        "id": "rM46Sl0tBj1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WER and CER"
      ],
      "metadata": {
        "id": "0clhP0hvG8aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Merged_VITS=pd.read_csv('/content/Merged_VITS.csv')\n",
        "Merged_VITS"
      ],
      "metadata": {
        "id": "QecQV-eJs6kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from jiwer import wer, cer\n",
        "\n",
        "def calculate_wer_cer_from_csv(csv_path):\n",
        "    \"\"\"\n",
        "    Calculate the average Word Error Rate (WER) and Character Error Rate (CER)\n",
        "    from a CSV file containing 'Transcribed Text' and 'Original Transcribed' columns.\n",
        "\n",
        "    Args:\n",
        "        csv_path (str): The path to the CSV file.\n",
        "    \"\"\"\n",
        "    wer_values = []\n",
        "    cer_values = []\n",
        "\n",
        "    with open(csv_path, mode='r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            transcribed_text = row['text']\n",
        "            original_text = row['Transcribed Text']\n",
        "            # Calculate WER and CER for this row and append to lists\n",
        "            wer_values.append(wer(original_text, transcribed_text))\n",
        "            cer_values.append(cer(original_text, transcribed_text))\n",
        "\n",
        "    # Calculate average WER and CER across all entries\n",
        "    average_wer = sum(wer_values) / len(wer_values)\n",
        "    average_cer = sum(cer_values) / len(cer_values)\n",
        "\n",
        "    print(f\"Average Word Error Rate (WER): {average_wer:.2f}\")\n",
        "    print(f\"Average Character Error Rate (CER): {average_cer:.2f}\")\n",
        "\n",
        "# Path to your CSV file\n",
        "csv_path = \"/content/Merged_VITS.csv\"\n",
        "\n",
        "# Calculate and print the average WER and CER\n",
        "calculate_wer_cer_from_csv(csv_path)\n"
      ],
      "metadata": {
        "id": "7EaRBF1tGzNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Merged_XTTS=pd.read_csv('/content/Merged_XTTS.csv')\n",
        "Merged_XTTS"
      ],
      "metadata": {
        "id": "hqBVTmRttLpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from jiwer import wer, cer\n",
        "\n",
        "def calculate_wer_cer_from_csv(csv_path):\n",
        "    \"\"\"\n",
        "    Calculate the average Word Error Rate (WER) and Character Error Rate (CER)\n",
        "    from a CSV file containing 'Transcribed Text' and 'Original Transcribed' columns.\n",
        "\n",
        "    Args:\n",
        "        csv_path (str): The path to the CSV file.\n",
        "    \"\"\"\n",
        "    wer_values = []\n",
        "    cer_values = []\n",
        "\n",
        "    with open(csv_path, mode='r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            transcribed_text = row['text']\n",
        "            original_text = row['Transcribed']\n",
        "            # Calculate WER and CER for this row and append to lists\n",
        "            wer_values.append(wer(original_text, transcribed_text))\n",
        "            cer_values.append(cer(original_text, transcribed_text))\n",
        "\n",
        "    # Calculate average WER and CER across all entries\n",
        "    average_wer = sum(wer_values) / len(wer_values)\n",
        "    average_cer = sum(cer_values) / len(cer_values)\n",
        "\n",
        "    print(f\"Average Word Error Rate (WER): {average_wer:.2f}\")\n",
        "    print(f\"Average Character Error Rate (CER): {average_cer:.2f}\")\n",
        "\n",
        "# Path to your CSV file\n",
        "csv_path = \"/content/Merged_XTTS.csv\"\n",
        "\n",
        "# Calculate and print the average WER and CER\n",
        "calculate_wer_cer_from_csv(csv_path)"
      ],
      "metadata": {
        "id": "uziiHINQtW1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Results\n",
        "models = ['VITS', 'xTTS']\n",
        "wer_values = [0.47, 0.32]  # WER for VITS and xTTS\n",
        "cer_values = [0.18, 0.10]  # CER for VITS and xTTS\n",
        "\n",
        "# Creating the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Setting the positions and width for the bars\n",
        "positions = range(len(models))\n",
        "width = 0.4  # the width of the bars\n",
        "\n",
        "# Plotting WER\n",
        "plt.bar([p - width / 2 for p in positions], wer_values, width, alpha=0.7, label='WER')\n",
        "\n",
        "# Plotting CER\n",
        "plt.bar([p + width / 2 for p in positions], cer_values, width, alpha=0.7, label='CER')\n",
        "\n",
        "# Adding some text for labels, title and custom x-axis tick labels, etc.\n",
        "plt.ylabel('Rates')\n",
        "plt.title('WER and CER Comparison between VITS and xTTS Models')\n",
        "plt.xticks(positions, models)\n",
        "plt.legend()\n",
        "\n",
        "# Adding numerical values on top of the bars for clarity\n",
        "for i in range(len(models)):\n",
        "    plt.text(i - width / 2, wer_values[i] + 0.02, f\"{wer_values[i]:.2f}\", ha='center')\n",
        "    plt.text(i + width / 2, cer_values[i] + 0.02, f\"{cer_values[i]:.2f}\", ha='center')\n",
        "\n",
        "plt.tight_layout()  # Adjusts the plot to ensure everything fits without overlap\n",
        "\n",
        "plt.show()  # Displays the plot\n"
      ],
      "metadata": {
        "id": "zRDnYZwPu810"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reuslt\n",
        "\n",
        "The comparative analysis between the VITS and xTTS text-to-speech models was conducted using Whisper large_v3 for speech-to-text transcription, aiming to evaluate the performance of synthesized audio outputs across various content categories. These categories included News, Dialogue, Education, Public Announcements, Accessibility, Advertisements, and Navigation. By transcribing the synthesized audios of these two models and calculating the Word Error Rate (WER) and Character Error Rate (CER), the study sought to provide a comprehensive understanding of each model's effectiveness in generating natural, accurate speech across a diverse range of applications.\n",
        "\n",
        "The results revealed that the xTTS model outperformed the VITS model in terms of both WER and CER, with the xTTS model achieving a WER of 0.32 and a CER of 0.10, compared to the VITS model's WER of 0.47 and CER of 0.18. This indicates that the xTTS model has a higher accuracy in mimicking human speech, making fewer mistakes in word selection and character representation in the transcribed text. Such findings suggest that the xTTS model may be more reliable for applications requiring high precision in speech synthesis, such as educational content, public announcements, and accessibility features, where clear and accurate communication is paramount.\n",
        "\n",
        "This comparison sheds light on the potential applications and suitability of each model for various tasks. The superior performance of the xTTS model, particularly in generating content for Education, Navigation, and Accessibility, highlights its capacity to produce more intelligible and natural-sounding speech. On the other hand, while the VITS model exhibits a higher error rate, it still holds value for applications where the ultimate realism and naturalness of the speech may not be as critical. This study underscores the importance of selecting the right text-to-speech model based on the specific needs of the application, ensuring that the synthesized audio meets the desired criteria for accuracy and intelligibility."
      ],
      "metadata": {
        "id": "k0_Znbr4vfty"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SZ9tA2SavjMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}